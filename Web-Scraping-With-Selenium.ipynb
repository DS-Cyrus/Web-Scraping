{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping of **LinkedIn profiles** is a very useful activity especially to achieve public relations / marketing tasks. Using Python you can make this process smoother, using your time to focus on those profiles that have critical peculiarities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** this tutorial(boot camp) presents practices that if applied in some circumstances might violate LinkedIn Terms and Conditions. It is reader’s responsibility to check LinkedIn Policy before proceeding in any way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, Web Scraping is a technique used to extract data from websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Note**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’ve ever copy and pasted information from a website, you’ve performed the same function as any web scraper, only on a microscopic, manual scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Technically web scraping can be performed in two ways:**\n",
    "\n",
    "**Direct HTTP requests:** best choice for static websites.\n",
    "\n",
    "\n",
    "**Driving a Web Browser:** best choice for dynamic websites with content asynchronously loaded or IFrames (unfortunatelly not so common as you may think, especially in legacy systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Direct HTTP Requests**\n",
    "As you may know, website are just a rendering of the HTML + CSS code that the web server returns as a result of a GET / POST request of your browser. As a result, a simple script can send automatically HTTP requests and parse the answer, scraping the content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1.01**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X GET http://www.wikipedia.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import pandas as pd\n",
    "#load html code from a url\n",
    "page = urllib.request.urlopen(\"https://docs.python.org/3/library/random.html\")\n",
    "soup = bs(page)\n",
    "\n",
    "#find all function names\n",
    "names = soup.body.findAll('dt')\n",
    "#print all function names\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Driving a Web Browser**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes websites loads part of the content asynchronously. This means that the information you want to scrape may not be contained in the first HTTP response, but they are loaded only as a consequence of a page scrolling eg. like LinkedIn or twitter case or after the click of a button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome this barrier, you can use a Web Browser Driver "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Web Browser drivers let you run a real web browser enabling your python scriptto emulate user behavior on the page, basically executing Javascript code through the browser console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way you can, for example, emulate the click on a button — assuming this is useful to the scraping activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```javascript\n",
    "document.getElementById('buttonID').click()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Selenium Web Driver**\n",
    "Selenium Web Driver is one of the best Web Browser Driver available for Python. It’s part of the Selenium framework which is a portable framework for testing web applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Loading the LinkedIn.com home page.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# Creation of a new instance of Google Chrome\n",
    "browser = webdriver.Chrome(executable_path='path/to/chromedriver/executable')\n",
    "\n",
    "# Load the page on the browser\n",
    "browser.get('https://www.linkedin.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Interacting with the page: how to run Javascript**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open a LinkedIn Profile page, you will realize that in order to scrape the email address is necessary to click on the ‘Contact info’ link, wait for a popup to load, and then — if provided by the user — you can see the email address and so or  eventually, scrape it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we must emulate such user interaction through some javascript:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Javascript code on webpage\n",
    "browser.execute_script(\n",
    "    \"(function(){try{for(i in document.getElementsByTagName('a')){let el = document.getElementsByTagName('a')[i]; \"\n",
    "    \"if(el.innerHTML.includes('Contact info')){el.click();}}}catch(e){}})()\")\n",
    "\n",
    "# Wait 5 seconds for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Scrape the email address from the 'Contact info' popup\n",
    "email = browser.execute_script(\n",
    "    \"return (function(){try{for (i in document.getElementsByClassName('pv-contact-info__contact-type')){ let el = \"\n",
    "    \"document.getElementsByClassName('pv-contact-info__contact-type')[i]; if(el.className.includes('ci-email')){ \"\n",
    "    \"return el.children[2].children[0].innerText; } }} catch(e){return '';}})()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Worthy noting info from Wikipedia:**\n",
    "\n",
    "**Selenium accepts commands, sent in Selenese, or via a Client API and sends them to a browser. This is implemented through a browser-specific browser driver, which sends commands to a browser and retrieves results.\n",
    "Selenium WebDriver does not need a special server to execute tests: instead, the WebDriver directly starts a browser instance and controls it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Full Project]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
